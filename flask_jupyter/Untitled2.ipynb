{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "engine = create_engine('sqlite:///recommender2.db', echo=False)\n",
    "\n",
    "for f in os.listdir('data/movies/ml-latest-small'):\n",
    "    if f[-4:] == '.csv':\n",
    "        data = pd.read_csv(f'data/movies/ml-latest-small/{f}')\n",
    "        data.to_sql(f[:-4], engine)\n",
    "        print(f[0:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_movie_id_list = ['70286', '109487', '589']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "movie_id_unique = 'SELECT * FROM movies'\n",
    "all_movies = pd.read_sql(movie_id_unique, engine)\n",
    "\n",
    "#remove the input movies from all_movies\n",
    "movies_not_watched = all_movies[~all_movies['movieId'].isin(watched_movie_id_list)]\n",
    "movies_not_watched.loc[:,'fake_id'] = np.ones(len(movies_not_watched), dtype =int)\n",
    "\n",
    "#get all_ratings from sqlite\n",
    "query = 'SELECT \"userId\", ratings.\"movieId\", movies.title, rating FROM ratings JOIN movies ON ratings.\"movieId\" = movies.\"movieId\";'\n",
    "all_ratings = pd.read_sql(query, engine)\n",
    "\n",
    "#remove the watched movies from all_ratings\n",
    "not_all_ratings = all_ratings[~all_ratings['movieId'].isin(watched_movie_id_list)]\n",
    "\n",
    "#remove movieId and ratings of the watched movies???\n",
    "movieindex = not_all_ratings['movieId'].unique().tolist()\n",
    "dl_movie2movie_encoded = {x: i for i, x in enumerate(movieindex)}\n",
    "dl_movie_encoded2movie = {i: x for i, x in enumerate(movieindex)}\n",
    "\n",
    "not_all_ratings.loc[:,\"movie\"] = not_all_ratings[\"movieId\"].map(dl_movie2movie_encoded)\n",
    "not_all_ratings.loc[:,\"rating\"] = not_all_ratings[\"rating\"].values.astype(np.float32)\n",
    "\n",
    "#map userId from ?? to not_all_ratings ?? what do i do with the users??\n",
    "\n",
    "not_all_user_ids = not_all_ratings[\"userId\"].unique().tolist()\n",
    "dl_user2user_encoded = {x: i for i, x in enumerate(not_all_user_ids)}\n",
    "dl_userencoded2user = {i: x for i, x in enumerate(not_all_user_ids)}\n",
    "\n",
    "not_all_ratings.loc[:,\"user\"] = not_all_ratings[\"userId\"].map(dl_user2user_encoded)\n",
    "\n",
    "min_rating = min(not_all_ratings[\"rating\"])\n",
    "max_rating = max(not_all_ratings[\"rating\"])\n",
    "num_users = len(dl_user2user_encoded)\n",
    "num_movies = len(dl_movie_encoded2movie)\n",
    "print(\n",
    "        \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "            num_users, num_movies, min_rating, max_rating\n",
    "        )\n",
    "    )\n",
    "\n",
    "#define training data\n",
    "df = not_all_ratings.sample(frac=1, random_state=42)\n",
    "x = not_all_ratings[[\"user\", \"movie\"]].values\n",
    "\n",
    "    # Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = not_all_ratings[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "    # Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "        x[:train_indices],\n",
    "        x[train_indices:],\n",
    "        y[:train_indices],\n",
    "        y[train_indices:],\n",
    "    )\n",
    "\n",
    "#inference\n",
    "user_movie_array = movies_not_watched[['fake_id','index']]\n",
    "max_movie_index = user_movie_array['index'].max()\n",
    "that = user_movie_array.to_numpy()\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "        def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "            super(RecommenderNet, self).__init__(**kwargs)\n",
    "            self.num_users = num_users\n",
    "            self.num_movies = num_movies\n",
    "            self.embedding_size = embedding_size\n",
    "            self.user_embedding = layers.Embedding(\n",
    "                num_users,\n",
    "                embedding_size,\n",
    "                embeddings_initializer=\"he_normal\",\n",
    "                embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "            )\n",
    "            self.user_bias = layers.Embedding(num_users, 1)\n",
    "            self.movie_embedding = layers.Embedding(\n",
    "            #change this line from num_movies to max_movie_index+1\n",
    "                max_movie_index+1,\n",
    "                embedding_size,\n",
    "                embeddings_initializer=\"he_normal\",\n",
    "                embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "            )\n",
    "            #and this line (input_dim)\n",
    "            self.movie_bias = layers.Embedding(max_movie_index+1, 1)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            user_vector = self.user_embedding(inputs[:, 0])\n",
    "            user_bias = self.user_bias(inputs[:, 0])\n",
    "            movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "            movie_bias = self.movie_bias(inputs[:, 1])\n",
    "            dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "            # Add all the components (including bias)\n",
    "            x = dot_user_movie + user_bias + movie_bias\n",
    "            # The sigmoid activation forces the rating to between 0 and 1\n",
    "            return tf.nn.sigmoid(x)\n",
    "            #return movie_bias\n",
    "\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
    "    )\n",
    "ratings = model.predict(that).flatten()\n",
    "\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "movies_not_watched.loc[movies_not_watched['index'].isin(top_ratings_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
