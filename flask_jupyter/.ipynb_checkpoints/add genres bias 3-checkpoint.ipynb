{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links\n",
      "ratings\n",
      "movies\n",
      "tags\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "engine = create_engine('sqlite:///recommender2.db', echo=False)\n",
    "\n",
    "for f in os.listdir('data/movies/ml-latest-small'):\n",
    "    if f[-4:] == '.csv':\n",
    "        data = pd.read_csv(f'data/movies/ml-latest-small/{f}')\n",
    "        data.to_sql(f[:-4], engine)\n",
    "        print(f[0:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_movie_id_list = ['70286', '109487', '589']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9721, Min rating: 0.5, Max rating: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>fake_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>3297</td>\n",
       "      <td>4462</td>\n",
       "      <td>18 Again! (1988)</td>\n",
       "      <td>Comedy|Fantasy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>3303</td>\n",
       "      <td>4470</td>\n",
       "      <td>Ariel (1988)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>3305</td>\n",
       "      <td>4473</td>\n",
       "      <td>Bat*21 (1988)</td>\n",
       "      <td>Drama|War</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>3310</td>\n",
       "      <td>4478</td>\n",
       "      <td>Biloxi Blues (1988)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>3315</td>\n",
       "      <td>4487</td>\n",
       "      <td>Cocktail (1988)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>3316</td>\n",
       "      <td>4488</td>\n",
       "      <td>Colors (1988)</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>3317</td>\n",
       "      <td>4489</td>\n",
       "      <td>Coming to America (1988)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>3322</td>\n",
       "      <td>4497</td>\n",
       "      <td>Dead Heat (1988)</td>\n",
       "      <td>Action|Comedy|Horror|Sci-Fi</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>3324</td>\n",
       "      <td>4499</td>\n",
       "      <td>Dirty Rotten Scoundrels (1988)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>3327</td>\n",
       "      <td>4504</td>\n",
       "      <td>Feds (1988)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  movieId                           title  \\\n",
       "3297   3297     4462                18 Again! (1988)   \n",
       "3303   3303     4470                    Ariel (1988)   \n",
       "3305   3305     4473                   Bat*21 (1988)   \n",
       "3310   3310     4478             Biloxi Blues (1988)   \n",
       "3315   3315     4487                 Cocktail (1988)   \n",
       "3316   3316     4488                   Colors (1988)   \n",
       "3317   3317     4489        Coming to America (1988)   \n",
       "3322   3322     4497                Dead Heat (1988)   \n",
       "3324   3324     4499  Dirty Rotten Scoundrels (1988)   \n",
       "3327   3327     4504                     Feds (1988)   \n",
       "\n",
       "                           genres  fake_id  prediction  \n",
       "3297               Comedy|Fantasy        1    0.534485  \n",
       "3303                        Drama        1    0.530543  \n",
       "3305                    Drama|War        1    0.534334  \n",
       "3310                 Comedy|Drama        1    0.533308  \n",
       "3315                Drama|Romance        1    0.532726  \n",
       "3316           Action|Crime|Drama        1    0.534500  \n",
       "3317               Comedy|Romance        1    0.530855  \n",
       "3322  Action|Comedy|Horror|Sci-Fi        1    0.534062  \n",
       "3324                       Comedy        1    0.530728  \n",
       "3327                       Comedy        1    0.530166  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "movie_id_unique = 'SELECT * FROM movies'\n",
    "all_movies = pd.read_sql(movie_id_unique, engine)\n",
    "\n",
    "#remove the input movies from all_movies\n",
    "movies_not_watched = all_movies[~all_movies['movieId'].isin(watched_movie_id_list)]\n",
    "movies_not_watched.loc[:,'fake_id'] = np.ones(len(movies_not_watched), dtype =int)\n",
    "\n",
    "#get all_ratings from sqlite\n",
    "query = 'SELECT \"userId\", ratings.\"movieId\", movies.title, rating FROM ratings JOIN movies ON ratings.\"movieId\" = movies.\"movieId\";'\n",
    "all_ratings = pd.read_sql(query, engine)\n",
    "\n",
    "#remove the watched movies from all_ratings\n",
    "not_all_ratings = all_ratings[~all_ratings['movieId'].isin(watched_movie_id_list)]\n",
    "\n",
    "#remove movieId and ratings of the watched movies???\n",
    "movieindex = not_all_ratings['movieId'].unique().tolist()\n",
    "dl_movie2movie_encoded = {x: i for i, x in enumerate(movieindex)}\n",
    "dl_movie_encoded2movie = {i: x for i, x in enumerate(movieindex)}\n",
    "\n",
    "not_all_ratings.loc[:,\"movie\"] = not_all_ratings[\"movieId\"].map(dl_movie2movie_encoded)\n",
    "not_all_ratings.loc[:,\"rating\"] = not_all_ratings[\"rating\"].values.astype(np.float32)\n",
    "\n",
    "#map userId from ?? to not_all_ratings ?? what do i do with the users??\n",
    "\n",
    "not_all_user_ids = not_all_ratings[\"userId\"].unique().tolist()\n",
    "dl_user2user_encoded = {x: i for i, x in enumerate(not_all_user_ids)}\n",
    "dl_userencoded2user = {i: x for i, x in enumerate(not_all_user_ids)}\n",
    "\n",
    "not_all_ratings.loc[:,\"user\"] = not_all_ratings[\"userId\"].map(dl_user2user_encoded)\n",
    "\n",
    "min_rating = min(not_all_ratings[\"rating\"])\n",
    "max_rating = max(not_all_ratings[\"rating\"])\n",
    "num_users = len(dl_user2user_encoded)\n",
    "num_movies = len(dl_movie_encoded2movie)\n",
    "print(\n",
    "        \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "            num_users, num_movies, min_rating, max_rating\n",
    "        )\n",
    "    )\n",
    "\n",
    "#define training data\n",
    "df = not_all_ratings.sample(frac=1, random_state=42)\n",
    "x = not_all_ratings[[\"user\", \"movie\"]].values\n",
    "\n",
    "    # Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = not_all_ratings[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "    # Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "        x[:train_indices],\n",
    "        x[train_indices:],\n",
    "        y[:train_indices],\n",
    "        y[train_indices:],\n",
    "    )\n",
    "\n",
    "#inference\n",
    "user_movie_array = movies_not_watched[['fake_id','index']]\n",
    "max_movie_index = user_movie_array['index'].max()\n",
    "that = user_movie_array.to_numpy()\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "        def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "            super(RecommenderNet, self).__init__(**kwargs)\n",
    "            self.num_users = num_users\n",
    "            self.num_movies = num_movies\n",
    "            self.embedding_size = embedding_size\n",
    "            self.user_embedding = layers.Embedding(\n",
    "                num_users,\n",
    "                embedding_size,\n",
    "                embeddings_initializer=\"he_normal\",\n",
    "                embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "            )\n",
    "            self.user_bias = layers.Embedding(num_users, 1)\n",
    "            self.movie_embedding = layers.Embedding(\n",
    "            #change this line from num_movies to max_movie_index+1\n",
    "                max_movie_index+1,\n",
    "                embedding_size,\n",
    "                embeddings_initializer=\"he_normal\",\n",
    "                embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "            )\n",
    "            #and this line (input_dim)\n",
    "            self.movie_bias = layers.Embedding(max_movie_index+1, 1)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            user_vector = self.user_embedding(inputs[:, 0])\n",
    "            user_bias = self.user_bias(inputs[:, 0])\n",
    "            movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "            movie_bias = self.movie_bias(inputs[:, 1])\n",
    "            dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "            # Add all the components (including bias)\n",
    "            x = dot_user_movie + user_bias + movie_bias\n",
    "            # The sigmoid activation forces the rating to between 0 and 1\n",
    "            return tf.nn.sigmoid(x)\n",
    "            #return movie_bias\n",
    "\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
    "    )\n",
    "ratings = model.predict(that).flatten()\n",
    "\n",
    "movies_not_watched.loc[:,'prediction'] = ratings\n",
    "highest_score = ratings[ratings.argsort()[-10:]][::-1]\n",
    "\n",
    "recom_movie_titles = movies_not_watched.loc[movies_not_watched.loc[:,'prediction'].isin(highest_score)]\n",
    "#movies_not_watched.loc[movies_not_watched['index'].isin(top_ratings_indices)]\n",
    "recom_movie_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first have to replace Sci-Fi with SciFi and Film-Noir with FilmNoir otherwise the len(np.unique(genres)) is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action', 'adventure', 'animation', 'children', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmnoir', 'horror', 'imax', 'musical', 'mystery', 'romance', 'scifi', 'thriller', 'war', 'western']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "all_movies['genres'].replace('Sci-Fi', 'SciFi', inplace=True, regex=True)\n",
    "all_movies['genres'].replace('Film-Noir', 'FilmNoir', inplace=True, regex=True)\n",
    "all_movies['genres'].replace('(no genres listed)', 'N/A', inplace=True, regex=True)\n",
    "all_movies['genres'][300:350]\n",
    "allgenres = all_movies['genres']\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "tfidf_matrix=tfidf_vectorizer.fit_transform(allgenres)\n",
    "\n",
    "print(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action|SciFi', 'Mystery|SciFi|Thriller', 'SciFi|IMAX']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liked_genres = all_movies.loc[all_movies['movieId'].isin(watched_movie_id_list), 'genres'].to_list()\n",
    "liked_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action', 'SciFi', 'Mystery', 'SciFi', 'Thriller', 'SciFi', 'IMAX']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted = [sub.split(\"|\") for sub in liked_genres]\n",
    "flat_list = []\n",
    "for sublist in splitted:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action', 'scifi', 'mystery', 'scifi', 'thriller', 'scifi', 'imax']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "for item in flat_list:\n",
    "    perrow = item.lower()\n",
    "    vocab.append(perrow)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "allgenres = all_movies['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "splittedgenres = [sub.split(\"|\") for sub in allgenres]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 0, 'scifi': 3, 'mystery': 2, 'thriller': 4, 'imax': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def vect_cos(vect, test_list):\n",
    "\n",
    "    \"\"\" Vectorise text and compute the cosine similarity \"\"\"\n",
    "    query_0 = vect.transform([' '.join(vect.get_feature_names())])\n",
    "    query_1 = vect.transform(test_list)\n",
    "    cos_sim = cosine_similarity(query_0.A, query_1.A)  # displays the resulting matrix\n",
    "    return query_1, np.round(cos_sim.squeeze(), 3)\n",
    "\n",
    "vectoriser3 = CountVectorizer().fit(vocab)\n",
    "vectoriser3.vocabulary_ # show the word-matrix position pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "see = []\n",
    "for item in splittedgenres[0]:\n",
    "    perrow = item.lower()\n",
    "    see.append(perrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure', 'animation', 'children', 'comedy', 'fantasy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The cosine similarity for the first list is 0.0.\n"
     ]
    }
   ],
   "source": [
    "see_vect, see_cos = vect_cos(vectoriser3, [' '.join(see)])\n",
    "print('\\nThe cosine similarity for the first list is {}.'.format(see_cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "see2 = []\n",
    "for item in splittedgenres[8856]:\n",
    "    perrow = item.lower()\n",
    "    see2.append(perrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comedy', 'crime', 'scifi']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The cosine similarity for the first list is 0.447.\n"
     ]
    }
   ],
   "source": [
    "see2_vect, see2_cos = vect_cos(vectoriser3, [' '.join(see2)])\n",
    "print('\\nThe cosine similarity for the first list is {}.'.format(see2_cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
